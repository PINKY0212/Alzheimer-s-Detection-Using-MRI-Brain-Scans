{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN/UcfumONBVK9jFqdRH/k8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"5_TgeuctjDQe"},"outputs":[],"source":["! mkdir ~/.kaggle"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"mzC7vCh5bBs9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json"],"metadata":{"id":"OIAoRFFJbEIr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cd /content/sample_data"],"metadata":{"id":"3WyUTfmObGUO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! kaggle datasets download -d tourist55/alzheimers-dataset-4-class-of-images"],"metadata":{"id":"NteCUgXlbIME"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! unzip /content/sample_data/alzheimers-dataset-4-class-of-images.zip"],"metadata":{"id":"IAG_vP3pbKp0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd \n","import os\n","\n","import copy\n","import warnings\n","warnings.filterwarnings('ignore')\n","import tensorflow as tf\n","import cv2\n","import keras\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.preprocessing.image import load_img, img_to_array\n","import matplotlib\n","import matplotlib.pylab as plt\n","import numpy as np\n","import seaborn as sns\n","from sklearn.utils import shuffle\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","from keras.applications.vgg16 import VGG16,preprocess_input"],"metadata":{"id":"Ps4MCcfrbOk2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["W = 32 # The default size for ResNet is 224 but resize to .5 to save memory size\n","H = 32 # The default size for ResNet is 224 but resize to .5 to save memory size\n","\n","label_to_class = {\n","    'MildDemented': 0,\n","    'ModerateDemented': 1,\n","    'NonDemented': 2,\n","    'VeryMildDemented':3\n","    \n","\n","}\n","class_to_label = {v: k for k, v in label_to_class.items()}\n","n_classes = len(label_to_class)\n","\n","def get_images(dir_name='../content/sample_data/Alzheimer_s Dataset/', label_to_class=label_to_class):\n","    \"\"\"read images / labels from directory\"\"\"\n","    \n","    Images = []\n","    Classes = []\n","    \n","    for j in ['/train','/test']:\n","        for label_name in os.listdir(dir_name+str(j)):\n","            cls = label_to_class[label_name]\n","\n","            for img_name in os.listdir('/'.join([dir_name+str(j), label_name])):\n","                img = load_img('/'.join([dir_name+str(j), label_name, img_name]), target_size=(W, H))\n","                img = img_to_array(img)\n","\n","                Images.append(img)\n","                Classes.append(cls)\n","            \n","    Images = np.array(Images, dtype=np.float32)\n","    Classes = np.array(Classes, dtype=np.float32)\n","    Images, Classes = shuffle(Images, Classes, random_state=0)\n","    \n","    return Images, Classes"],"metadata":{"id":"4RAhwnBwbVR-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cd /content"],"metadata":{"id":"h0UBUzhxbgSN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## get images / labels\n","\n","Images, Classes = get_images()\n","\n","Images.shape, Classes.shape"],"metadata":{"id":"C_nYllJgbios"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## split train / test\n","\n","indices_train, indices_test = train_test_split(list(range(Images.shape[0])), train_size=0.8, test_size=0.2, shuffle=True)\n","\n","x_train = Images[indices_train]\n","y_train = Classes[indices_train]\n","x_test = Images[indices_test]\n","y_test = Classes[indices_test]\n","\n","x_train.shape, y_train.shape, x_test.shape, y_test.shape"],"metadata":{"id":"qjwOl8BibnMW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.utils import np_utils"],"metadata":{"id":"vN9w9URbbwB2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train = keras.utils.np_utils.to_categorical(y_train, n_classes)\n","y_test = keras.utils.np_utils.to_categorical(y_test, n_classes)\n","\n","y_train.shape, y_test.shape"],"metadata":{"id":"4QU-QP0pbwme"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install -U tensorflow-addons"],"metadata":{"id":"ov3nozzcb13O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import tensorflow_addons as tfa"],"metadata":{"id":"SBvz_RN1b4Y9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_classes = 4\n","input_shape = (32, 32, 3)"],"metadata":{"id":"n8xkI7dqb-p1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["v = CaiT(\n","    image_size = 128,\n","    patch_size = 12,\n","    num_classes = 4,\n","    dim = 1024,\n","    depth = 12,             # depth of transformer for patch to patch attention only\n","    cls_depth = 2,          # depth of cross attention of CLS tokens to patch\n","    heads = 16,\n","    mlp_dim = 2048,\n","    dropout = 0.1,\n","    emb_dropout = 0.1,\n","    layer_dropout = 0.05    # randomly dropout 5% of the layers\n",")\n","img = tf.random.normal(shape=[1, 256, 256, 3])\n","preds = v(img) # (1, 1000)"],"metadata":{"id":"t6gqofmacFhi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#data augmentation\n","data_augmentation = keras.Sequential(\n","    [\n","        layers.Normalization(),\n","        layers.Resizing(image_size, image_size),\n","        layers.RandomFlip(\"horizontal\"),\n","        layers.RandomRotation(factor=0.02),\n","        layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n","    ],\n","    name=\"data_augmentation\",\n",")\n","# Compute the mean and the variance of the training data for normalization.\n","data_augmentation.layers[0].adapt(x_train)"],"metadata":{"id":"HVkeIpwMcRg4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Implement patch creation as a layer\n","class Patches(layers.Layer):\n","    def __init__(self, patch_size):\n","        super(Patches, self).__init__()\n","        self.patch_size = patch_size\n","\n","    def call(self, images):\n","        batch_size = tf.shape(images)[0]\n","        patches = tf.image.extract_patches(\n","            images=images,\n","            sizes=[1, self.patch_size, self.patch_size, 1],\n","            strides=[1, self.patch_size, self.patch_size, 1],\n","            rates=[1, 1, 1, 1],\n","            padding=\"VALID\",\n","        )\n","        patch_dims = patches.shape[-1]\n","        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n","        return patches"],"metadata":{"id":"dFZculyRcfhM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#display a patch\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(4, 4))\n","image = x_train[np.random.choice(range(x_train.shape[0]))]\n","plt.imshow(image.astype(\"uint8\"))\n","plt.axis(\"off\")\n","\n","resized_image = tf.image.resize(\n","    tf.convert_to_tensor([image]), size=(image_size, image_size)\n",")\n","patches = Patches(patch_size)(resized_image)\n","print(f\"Image size: {image_size} X {image_size}\")\n","print(f\"Patch size: {patch_size} X {patch_size}\")\n","print(f\"Patches per image: {patches.shape[1]}\")\n","print(f\"Elements per patch: {patches.shape[-1]}\")\n","\n","n = int(np.sqrt(patches.shape[1]))\n","plt.figure(figsize=(4, 4))\n","for i, patch in enumerate(patches[0]):\n","    ax = plt.subplot(n, n, i + 1)\n","    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n","    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n","    plt.axis(\"off\")"],"metadata":{"id":"OoD5CPxOczKo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# the patch encoding layer\n","class PatchEncoder(layers.Layer):\n","    def __init__(self, num_patches, projection_dim):\n","        super(PatchEncoder, self).__init__()\n","        self.num_patches = num_patches\n","        self.projection = layers.Dense(units=projection_dim)\n","        self.position_embedding = layers.Embedding(\n","            input_dim=num_patches, output_dim=projection_dim\n","        )\n","\n","    def call(self, patch):\n","        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n","        encoded = self.projection(patch) + self.position_embedding(positions)\n","        return encoded"],"metadata":{"id":"7PV2XvxOeH8s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import einsum\n","from tensorflow.keras import Model\n","from tensorflow.keras.layers import Layer\n","from tensorflow.keras import Sequential\n","import tensorflow.keras.layers as nn\n","\n","from einops import rearrange, repeat\n","from einops.layers.tensorflow import Rearrange\n","\n","from random import randrange\n","import numpy as np\n","\n","def exists(val):\n","    return val is not None\n","\n","def dropout_layers(layers, dropout):\n","    if dropout == 0:\n","        return layers\n","\n","    num_layers = len(layers)\n","\n","    to_drop = np.random.uniform(low=0.0, high=1.0, size=[num_layers]) < dropout\n","\n","    # make sure at least one layer makes it\n","    if all(to_drop):\n","        rand_index = randrange(num_layers)\n","        to_drop[rand_index] = False\n","\n","    layers = [layer for (layer, drop) in zip(layers, to_drop) if not drop]\n","    return layers\n","\n","class LayerScale(Layer):\n","    def __init__(self, dim, fn, depth):\n","        super(LayerScale, self).__init__()\n","        if depth <= 18: # epsilon detailed in section 2 of paper\n","            init_eps = 0.1\n","        elif depth > 18 and depth <= 24:\n","            init_eps = 1e-5\n","        else:\n","            init_eps = 1e-6\n","\n","        scale = tf.fill(dims=[1, 1, dim], value=init_eps)\n","        self.scale = tf.Variable(scale)\n","        self.fn = fn\n","\n","    def call(self, x, training=True, **kwargs):\n","        return self.fn(x, training=training, **kwargs) * self.scale\n","\n","class PreNorm(Layer):\n","    def __init__(self, fn):\n","        super(PreNorm, self).__init__()\n","\n","        self.norm = nn.LayerNormalization()\n","        self.fn = fn\n","\n","    def call(self, x, training=True, **kwargs):\n","        return self.fn(self.norm(x), training=training, **kwargs)\n","\n","class MLP(Layer):\n","    def __init__(self, dim, hidden_dim, dropout=0.0):\n","        super(MLP, self).__init__()\n","        def GELU():\n","            def gelu(x, approximate=False):\n","                if approximate:\n","                    coeff = tf.cast(0.044715, x.dtype)\n","                    return 0.5 * x * (1.0 + tf.tanh(0.7978845608028654 * (x + coeff * tf.pow(x, 3))))\n","                else:\n","                    return 0.5 * x * (1.0 + tf.math.erf(x / tf.cast(1.4142135623730951, x.dtype)))\n","\n","            return nn.Activation(gelu)\n","\n","        self.net = [\n","            nn.Dense(units=hidden_dim),\n","            GELU(),\n","            nn.Dropout(rate=dropout),\n","            nn.Dense(units=dim),\n","            nn.Dropout(rate=dropout)\n","        ]\n","        self.net = Sequential(self.net)\n","\n","    def call(self, x, training=True):\n","        return self.net(x, training=training)\n","\n","class Attention(Layer):\n","    def __init__(self, dim, heads=8, dim_head=64, dropout=0.0):\n","        super(Attention, self).__init__()\n","        inner_dim = dim_head * heads\n","\n","        self.heads = heads\n","        self.scale = dim_head ** -0.5\n","\n","        self.attend = nn.Softmax()\n","        self.to_q = nn.Dense(units=inner_dim, use_bias=False)\n","        self.to_kv = nn.Dense(units=inner_dim * 2, use_bias=False)\n","\n","        self.mix_heads_pre_attn = tf.Variable(initial_value=tf.random.normal([heads, heads]))\n","        self.mix_heads_post_attn = tf.Variable(initial_value=tf.random.normal([heads, heads]))\n","\n","        self.to_out = [\n","            nn.Dense(units=dim),\n","            nn.Dropout(rate=dropout)\n","        ]\n","\n","        self.to_out = Sequential(self.to_out)\n","\n","    def call(self, x, context=None, training=True):\n","\n","        if not exists(context):\n","            context = x\n","        else:\n","            context = tf.concat([x, context], axis=1)\n","\n","        q = self.to_q(x)\n","        kv = self.to_kv(context)\n","        k, v = tf.split(kv, num_or_size_splits=2, axis=-1)\n","        qkv = (q, k, v)\n","\n","        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h=self.heads), qkv)\n","\n","        dots = einsum('b h i d, b h j d -> b h i j', q, k) * self.scale\n","\n","        dots = einsum('b h i j, h g -> b g i j', dots, self.mix_heads_pre_attn)  # talking heads, pre-softmax\n","        attn = self.attend(dots)\n","        attn = einsum('b h i j, h g -> b g i j', attn, self.mix_heads_post_attn)  # talking heads, post-softmax\n","\n","        x = tf.matmul(attn, v)\n","        x = rearrange(x, 'b h n d -> b n (h d)')\n","        x = self.to_out(x, training=training)\n","\n","        return x\n","\n","class Transformer(Layer):\n","    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout=0.0, layer_dropout=0.0):\n","        super(Transformer, self).__init__()\n","\n","        self.layers = []\n","        self.layer_dropout = layer_dropout\n","\n","        for ind in range(depth):\n","            self.layers.append([\n","                LayerScale(dim, PreNorm(Attention(dim, heads=heads, dim_head=dim_head, dropout=dropout)), depth=ind+1),\n","                LayerScale(dim, PreNorm(MLP(dim, mlp_dim, dropout=dropout)), depth=ind+1)\n","            ])\n","\n","    def call(self, x, context=None, training=True):\n","        layers = dropout_layers(self.layers, dropout=self.layer_dropout)\n","\n","        for attn, mlp in layers:\n","            x = attn(x, context=context, training=training) + x\n","            x = mlp(x, training=training) + x\n","\n","        return x\n","\n","class CaiT(Model):\n","    def __init__(self, image_size, patch_size, num_classes, dim, depth, cls_depth, heads, mlp_dim,\n","                 dim_head=64, dropout=0.0, emb_dropout=0.0, layer_dropout=0.0):\n","        super(CaiT, self).__init__()\n","\n","        assert image_size % patch_size == 0, 'Image dimensions must be divisible by the patch size.'\n","        num_patches = (image_size // patch_size) ** 2\n","\n","        self.patch_embedding = Sequential([\n","            Rearrange('b (h p1) (w p2) c -> b (h w) (p1 p2 c)', p1=patch_size, p2=patch_size),\n","            nn.Dense(units=dim)\n","        ], name='patch_embedding')\n","\n","        self.pos_embedding = tf.Variable(initial_value=tf.random.normal([1, num_patches, dim]))\n","        self.cls_token = tf.Variable(initial_value=tf.random.normal([1, 1, dim]))\n","        self.dropout = nn.Dropout(rate=emb_dropout)\n","\n","        self.patch_transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout, layer_dropout)\n","        self.cls_transformer = Transformer(dim, cls_depth, heads, dim_head, mlp_dim, dropout, layer_dropout)\n","\n","        self.mlp_head = Sequential([\n","            nn.LayerNormalization(),\n","            nn.Dense(units=num_classes)\n","        ], name='mlp_head')\n","\n","    def call(self, img, training=True, **kwargs):\n","        x = self.patch_embedding(img)\n","        b, n, d = x.shape\n","\n","        x += self.pos_embedding[:, :n]\n","        x = self.dropout(x, training=training)\n","\n","        x = self.patch_transformer(x, training=training)\n","\n","        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b=b)\n","        x = self.cls_transformer(cls_tokens, context=x, training=training)\n","\n","        x = self.mlp_head(x[:, 0])\n","\n","        return x"],"metadata":{"id":"HSVn3K46bemF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_cait_classifier():\n","    inputs = layers.Input(shape=input_shape)\n","    # Augment data.\n","    augmented = data_augmentation(inputs)\n","    # Create patches.\n","    patches = Patches(patch_size)(augmented)\n","    # Encode patches.\n","    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n","      \n","    # Create a [batch_size, projection_dim] tensor.\n","    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n","    representation = layers.Flatten()(representation)\n","    representation = layers.Dropout(0.5)(representation)\n","\n","    # Add MLP.\n","    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n","    # Classify outputs.\n","    logits = layers.Dense(num_classes)(features)\n","    # Create the Keras model.\n","    model = keras.Model(inputs=inputs, outputs=logits)\n","    return model"],"metadata":{"id":"4RFyXPqReJ1r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def run_experiment(model):\n","    optimizer = tfa.optimizers.AdamW(\n","        learning_rate=learning_rate, weight_decay=weight_decay\n","    )\n","\n","    model.compile(\n","        optimizer=optimizer,\n","        loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n","        metrics=[\n","            keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n","            keras.metrics.TopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n","        ],\n","    )\n","\n","    checkpoint_filepath = \"/tmp/checkpoint\"\n","    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n","        checkpoint_filepath,\n","        monitor=\"val_accuracy\",\n","        save_best_only=True,\n","        save_weights_only=True,\n","    )\n","\n","    history = model.fit(\n","        x=x_train,\n","        y=y_train,\n","        batch_size=batch_size,\n","        epochs=num_epochs,\n","        validation_split=0.1,\n","        callbacks=[checkpoint_callback] )\n","\n","    model.load_weights(checkpoint_filepath)\n","    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n","    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n","    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n","\n","    return history\n","\n","\n","cait_classifier = create_cait_classifier()\n","history = run_experiment(cait_classifier)"],"metadata":{"id":"hD1ZejqYdMI0"},"execution_count":null,"outputs":[]}]}